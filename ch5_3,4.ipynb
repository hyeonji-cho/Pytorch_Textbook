{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 5.3.1 특성 추출"
      ],
      "metadata": {
        "id": "4bLPIsGtJeCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 라이브러리 호출"
      ],
      "metadata": {
        "id": "7dEECUgTJo9n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CqY3elrJNaq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import glob\n",
        "import cv2  # OpenCV 라이브러리\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torchvision  # 컴퓨터 비전 용도의 패키지\n",
        "import torchvision.transforms as transforms  # 데이터 전처리를 위해 사용되는 패키지\n",
        "import torchvision.models as models  # 다양한 파이토치 네트워크를 사용할 수 있도록 도와주는 패키지\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 불러오기"
      ],
      "metadata": {
        "id": "tvX-vDf0KBPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files # 데이터 불러오기\n",
        "file_uploaded=files.upload()   # 데이터 불러오기: chap05/data/catndog.zip 파일 선택"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "id": "P3LSmKXcKEIz",
        "outputId": "29ff22e6-0e5f-48dc-ae3b-126a430f45b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8dc39ec2-2017-4a55-a4ac-eb1b6541502b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8dc39ec2-2017-4a55-a4ac-eb1b6541502b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip catanddog.zip -d catanddog/    #catanddog 폴더 만들어 압축 풀기"
      ],
      "metadata": {
        "id": "GCrcOhjGKREH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이미지 데이터 전처리 방법 정의"
      ],
      "metadata": {
        "id": "VHjUk6rRKK4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'catanddog/train/'\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.Resize([256, 256]),  # 256x256 크기로 조정\n",
        "                    transforms.RandomResizedCrop(224),  # 이미지를 임의로 자르고 크기를 조절하여 최종적으로 224x224 크기의 이미지를 생성\n",
        "                    transforms.RandomHorizontalFlip(),  # 이미지를 랜덤하게 수평으로 뒤집음\n",
        "                    transforms.ToTensor(),  # 이미지 데이터를 텐서로 변환\n",
        "                ])\n",
        "train_dataset = torchvision.datasets.ImageFolder(  # 데이터로더가 데이터를 불러올 대상과 방법 정의\n",
        "    data_path,\n",
        "    transform=transform\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(  # 데이터로더 - 데이터를 불러오는 부분\n",
        "    train_dataset,  # 데이터셋 지정\n",
        "    batch_size=32,  # 한 번에 불러올 데이터양\n",
        "    num_workers=8,  # 데이터를 불러올 때 하위 프로세스를 몇 개 사용할지\n",
        "    shuffle=True  # 데이터를 무작위로 섞을 것인지\n",
        ")\n",
        "\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "QAKzI8F7Krqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습에 사용될 이미지 출력"
      ],
      "metadata": {
        "id": "dlYgu-d9N88y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# train_loader로부터 배치를 가져옴 (데이터를 하나씩 꺼내옴)\n",
        "data_iter = iter(train_loader)\n",
        "samples, labels = next(data_iter)\n",
        "\n",
        "classes = {0:'cat', 1:'dog'}\n",
        "fig = plt.figure(figsize=(16,24))  # 생성된 figure의 크기 지정\n",
        "\n",
        "# 이미지 데이터 시각화\n",
        "for i in range(24):  # 24개의 이미지 데이터 출력\n",
        "    a = fig.add_subplot(4,6,i+1)  # 4x6 그리드에 i+1번째 서브플롯 추가\n",
        "    a.set_title(classes[labels[i].item()])  # 서브플롯의 제목 설정 (이미지의 클래스 레이블로)\n",
        "    a.axis('off')  # 축 숨김\n",
        "    a.imshow(np.transpose(samples[i].numpy(), (1,2,0)))  # 이미지 데이터 시각화, (세로, 가로, 채널)\n",
        "\n",
        "plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)"
      ],
      "metadata": {
        "id": "ciUu-QjHOZh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 사전 훈련된 모델 내려받기"
      ],
      "metadata": {
        "id": "2C6grsw9XV8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18(pretrained=True)  # 사전 학습된 가중치를 사용하겠음"
      ],
      "metadata": {
        "id": "EJOizQn8XYEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 사전 훈련된 모델의 파라미터 학습 유무 지정"
      ],
      "metadata": {
        "id": "uQESWvhaYQ3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting=True):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False  # 역전파 중 파라미터들에 대한 변화를 계산할 필요 없음\n",
        "\n",
        "set_parameter_requires_grad(resnet18)  # resnet18 모델의 파라미터를 역전파 중 동결시킴"
      ],
      "metadata": {
        "id": "NYBmuHJ3YUGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ResNet18에 완전연결층 추가"
      ],
      "metadata": {
        "id": "T9IyG7SHcf8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet-18 모델의 마지막 합성곱층의 출력 크기 = 512\n",
        "resnet18.fc = nn.Linear(512, 2)  # 클래스가 2개"
      ],
      "metadata": {
        "id": "sbpXRg9qclZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델의 파라미터 값 확인"
      ],
      "metadata": {
        "id": "gXfcRy5lcsIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in resnet18.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)"
      ],
      "metadata": {
        "id": "J6gBOGlIdd10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 객체 생성 및 손실 함수 정의"
      ],
      "metadata": {
        "id": "5TYF30jvdSo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained = True)  # 모델의 객체 생성\n",
        "\n",
        "for param in model.parameters():  # 모델의 합성곱층 가중치 고정\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = torch.nn.Linear(512, 2)\n",
        "for param in model.fc.parameters():  # 완전연결층 학습\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer = torch.optim.Adam(model.fc.parameters())\n",
        "cost = torch.nn.CrossEntropyLoss()  # 손실 함수 정의\n",
        "print(model)"
      ],
      "metadata": {
        "id": "TTYJo4MHdaIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 학습을 위한 함수 생성"
      ],
      "metadata": {
        "id": "VKRyjdWwesQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=13, is_train=True):\n",
        "    since = time.time()  # 현재 시간 기록\n",
        "    acc_history = []  # 정확도 기록 리스트\n",
        "    loss_history = []  # 손실 기록 리스트\n",
        "    best_acc = 0.0  # 최고 정확도 초기화\n",
        "\n",
        "    for epoch in range(num_epochs):  # 에포크만큼 반복\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        running_loss = 0.0  # 에포크마다 손실 초기화\n",
        "        running_corrects = 0  # 에포크마다 정확도 초기화\n",
        "\n",
        "        for inputs, labels in dataloaders:  # 데이터로더에 전달된 데이터만큼 반복\n",
        "            inputs = inputs.to(device)  # 입력 데이터를 지정된 장치로 이동\n",
        "            labels = labels.to(device)  # 레이블 데이터를 지정된 장치로 이동\n",
        "\n",
        "            model.to(device)  # 모델을 지정된 장치로 이동\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)  # 손실 계산\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)  # 현재 미니배치의 손실 값 * 배치 크기 = 현재 미니배치에 대한 총 손실\n",
        "            running_corrects += torch.sum(preds == labels.data)  # 정확한 예측 수 누적\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloaders.dataset)  # 평균 손실 계산\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)  # 평균 정확도 계산\n",
        "\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "\n",
        "        acc_history.append(epoch_acc.item())\n",
        "        loss_history.append(epoch_loss)\n",
        "        torch.save(model.state_dict(), os.path.join('catanddog/', '{0:0=2d}.pth'.format(epoch)))  # 모델 상태 저장\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since  # 걸린 시간 계산\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))  # 훈련 시간 출력\n",
        "    print('Best Acc: {:4f}'.format(best_acc))  # 최고 정확도 출력\n",
        "    return acc_history, loss_history  # 정확도와 손실 기록 리스트 반환"
      ],
      "metadata": {
        "id": "XhGGnFrEexG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 파라미터 학습 결과를 옵티마이저에 전달"
      ],
      "metadata": {
        "id": "u0lRu2R45aB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = []\n",
        "for name,param in resnet18.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)  # 파라미터 학습 결과를 저장\n",
        "        print(\"\\t\",name)\n",
        "\n",
        "optimizer = optim.Adam(params_to_update)  # 학습 결과를 옵티마이저에 전달"
      ],
      "metadata": {
        "id": "co7Cvftse-nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 학습"
      ],
      "metadata": {
        "id": "Sge1bM436vBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()  # 손실 함수 지정\n",
        "train_acc_hist, train_loss_hist = train_model(resnet18, train_loader, criterion, optimizer, device)"
      ],
      "metadata": {
        "id": "eUykB3rdfDiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 테스트 데이터 호출 및 전처리"
      ],
      "metadata": {
        "id": "BFMxvqFp6_xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = 'catanddog/test/'\n",
        "\n",
        "transform = transforms.Compose(\n",
        "                [\n",
        "                    transforms.Resize(224),\n",
        "                    transforms.CenterCrop(224),\n",
        "                    transforms.ToTensor(),\n",
        "                ])\n",
        "test_dataset = torchvision.datasets.ImageFolder(\n",
        "    root=test_path,\n",
        "    transform=transform\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "id": "ITe1X9PSfE-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 테스트 데이터 평가 함수 생성"
      ],
      "metadata": {
        "id": "UQs0Yv3-7Gcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, dataloaders, device):\n",
        "    since = time.time()  # 시작 시간 기록\n",
        "    acc_history = []  # 정확도 기록 리스트 초기화\n",
        "    best_acc = 0.0  # 최고 정확도 초기화\n",
        "\n",
        "    saved_models = glob.glob('catanddog/' + '*.pth')  # 'catanddog/' 경로에서 pth 확장자를 가진 파일 목록 가져오기\n",
        "    saved_models.sort()  # 불러온 .pth 파일들을 정렬\n",
        "    print('saved_model', saved_models)  # 불러온 모델 경로 출력\n",
        "\n",
        "    for model_path in saved_models:  # 각 불러온 모델에 대해 반복\n",
        "        print('Loading model', model_path)  # 현재 불러온 모델 경로 출력\n",
        "\n",
        "        model.load_state_dict(torch.load(model_path))  # 모델의 상태 불러오기\n",
        "        model.eval()  # 평가 모드로 설정\n",
        "        model.to(device)  # 지정된 장치로 모델 이동\n",
        "        running_corrects = 0  # 정확하게 예측된 샘플 수 초기화\n",
        "\n",
        "        for inputs, labels in dataloaders:  # 데이터로더에서 전달된 데이터에 대해 반복\n",
        "            inputs = inputs.to(device)  # 입력 데이터를 지정된 장치로 이동\n",
        "            labels = labels.to(device)  # 레이블 데이터를 지정된 장치로 이동\n",
        "\n",
        "            with torch.no_grad():  # 그래디언트 계산 비활성화\n",
        "                outputs = model(inputs)  # 모델로부터 예측값 얻기\n",
        "\n",
        "            _, preds = torch.max(outputs.data, 1)  # 예측 클래스 결정\n",
        "            preds[preds >= 0.5] = 1  # 0.5 이상의 값은 1로 설정\n",
        "            preds[preds < 0.5] = 0  # 0.5 미만의 값은 0으로 설정\n",
        "            running_corrects += preds.eq(labels).int().sum()  # 정확하게 예측된 샘플 수 누적\n",
        "\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)  # 정확도 계산\n",
        "        print('Acc: {:.4f}'.format(epoch_acc))  # 현재 모델의 정확도 출력\n",
        "\n",
        "        if epoch_acc > best_acc:  # 현재 정확도가 최고 정확도보다 높으면\n",
        "            best_acc = epoch_acc  # 최고 정확도 갱신\n",
        "\n",
        "        acc_history.append(epoch_acc.item())  # 정확도 기록 리스트에 현재 정확도 추가\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since  # 걸린 시간 계산\n",
        "    print('Validation complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))  # 검증 시간 출력\n",
        "    print('Best Acc: {:4f}'.format(best_acc))  # 최고 정확도 출력\n",
        "\n",
        "    return acc_history  # 정확도 기록 리스트 반환\n"
      ],
      "metadata": {
        "id": "f7dWclYqfKYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 테스트 데이터를 평가 함수에 적용"
      ],
      "metadata": {
        "id": "RFWAX4b67KwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc_hist = eval_model(resnet18, test_loader, device)"
      ],
      "metadata": {
        "id": "gujbxLLIfK-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 훈련과 테스트 데이터의 정확도를 그래프로 확인"
      ],
      "metadata": {
        "id": "ECaTrdWY-VSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc_hist)\n",
        "plt.plot(val_acc_hist)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SHqTTPbIfm3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 훈련 데이터의 오차에 대한 그래프 확인"
      ],
      "metadata": {
        "id": "bZbv6mNk-ZiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss_hist)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LpVNs1pMfs5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 실제로 데이터를 잘 예측하는지 확인"
      ],
      "metadata": {
        "id": "BizJ_Uxq-pw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 예측 이미지 출력을 위한 전처리 함수"
      ],
      "metadata": {
        "id": "HW8XZeVU-iJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def im_convert(tensor):\n",
        "    image=tensor.clone().detach().numpy()  # 기울기에 영향을 주지 않는 기존 텐서를 복사한 새로운 텐서 생성\n",
        "    image=image.transpose(1,2,0) # 이미지 차원을 변경하여 채널을 마지막으로 이동\n",
        "    image=image*(np.array((0.5,0.5,0.5))+np.array((0.5,0.5,0.5)))  # 이미지를 정규화된 값으로 변환\n",
        "    image=image.clip(0,1)  # image 데이터를 0과 1 사이의 값으로 제한하겠다 - 클리핑\n",
        "    return image"
      ],
      "metadata": {
        "id": "NsLSDy9BfwT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 개와 고양이 예측 결과 출력"
      ],
      "metadata": {
        "id": "pQvClg3PEfbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = {0:'cat', 1:'dog'}  # 개와 고양이 두 개에 대한 레이블\n",
        "\n",
        "dataiter=iter(test_loader)  # 테스트 데이터셋 가져오기\n",
        "images,labels=next(dataiter)  # 테스트 데이터셋에서 이미지와 레이블을 분리하여 가져오기\n",
        "\n",
        "output = model(images)  # 모델을 사용하여 출력 예측값 계산\n",
        "_, preds = torch.max(output, 1)  # 가장 높은 확률을 가진 클래스의 인덱스 찾기\n",
        "\n",
        "fig = plt.figure(figsize=(25, 4))  # 시각화할 그림의 크기 설정\n",
        "for idx in np.arange(20):\n",
        "    ax=fig.add_subplot(2,10,idx+1,xticks=[],yticks=[])  # 행의 수, 열의 수, 인덱스, tick삭제\n",
        "    plt.imshow(im_convert(images[idx]))  # 위에서 정의한 이미지 출력 함수\n",
        "    a.set_title(classes[labels[i].item()])\n",
        "    ax.set_title(\"{}({})\".format(str(classes[preds[idx].item()]),str(classes[labels[idx].item()])),  # 서브 플롯 제목 설정, 예측 클래스와 실제 클래스 표시\n",
        "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))  # preds[idx].item() 값이 0-고양이, 1-개, 정확한 예측이면 녹색, 그렇지 않으면 빨간색으로 표시\n",
        "plt.show()\n",
        "plt.subplots_adjust(bottom=0.2, top=0.6, hspace=0)  # 서브 플롯의 간격 조정"
      ],
      "metadata": {
        "id": "IwfCGUFsf3CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.4.1 특성 맵 시각화"
      ],
      "metadata": {
        "id": "YPd5f4msbske"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 필요한 라이브러리 호출"
      ],
      "metadata": {
        "id": "dSvd2Hi_bwkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "lMPj_EUwbvUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 설명 가능한 네트워크 생성\n",
        "- 13개의 합성곱층과 2개의 완전연결층으로 구성된 네트워크 생성\n",
        "- 렐루 활성화 함수 사용"
      ],
      "metadata": {
        "id": "rVWc4aW7cEqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XAI(torch.nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(XAI, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, bias=False),  # 입력채널, 출력채널, 커널, 편향사용X, (64, 222, 222)\n",
        "            nn.BatchNorm2d(64),  # 입력 채널이 64개인 2D 이미지 데이터에 대한 배치 정규화\n",
        "            nn.ReLU(inplace=True),  # 활성화 함수 통과, 기존의 데이터를 연산의 결괏값으로 대체한다\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 이미지 크기 절반 (64, 111, 111)\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 이미지 크기 절반 (128, 56, 56)\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 이미지 크기 절반 (256, 28, 28)\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 이미지 크기 절반 (512, 14, 14)\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding = 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 이미지 크기 절반 (512, 7, 7)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 512, bias=False),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)  # (512, 7, 7)\n",
        "        x = x.view(-1, 512)  # nn.Linear(512, 512)를 거치기 위해 (N,512)으로 맞춰줌\n",
        "        x = self.classifier(x)\n",
        "        return F.log_softmax(x)  # 신경망 말단의 결괏값들을 확률 개념으로 해석"
      ],
      "metadata": {
        "id": "C7Z1nQ-ucxtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 객체화"
      ],
      "metadata": {
        "id": "myFPFHQoLAvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=XAI()  # model이라는 이름의 객체 생성\n",
        "model.cpu() # 모델에 입력되는 이미지를 넘파이로 받아오는 부분때문에 CPU를 사용하도록 지정하였습니다\n",
        "model.eval() # 테스트 데이터에 대한 모델 평가 용도로 사용"
      ],
      "metadata": {
        "id": "iNwVGcfBcvVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 특성 맵을 확인하기 위한 클래스 정의"
      ],
      "metadata": {
        "id": "N2Ea-q_ULZvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerActivations:\n",
        "    features=[]  # 레이어 활성화 값을 저장할 리스트를 초기화합니다.\n",
        "    def __init__(self, model, layer_num):  # 클래스 생성자입니다. 모델과 레이어 번호를 받습니다.\n",
        "        self.hook = model[layer_num].register_forward_hook(self.hook_fn)  # 선택한 레이어에 대한 forward hook을 등록합니다.\n",
        "\n",
        "    def hook_fn(self, module, input, output):  # forward hook이 실행될 때 호출될 함수입니다.\n",
        "        output = output  # 출력을 저장합니다.\n",
        "        #self.features = output.to(device).detach().numpy()  # 출력을 디바이스에 전송하고 NumPy 배열로 변환하여 활성화 값 리스트에 저장합니다.\n",
        "        self.features = output.detach().numpy()  # 출력을 NumPy 배열로 변환하여 활성화 값 리스트에 저장합니다.\n",
        "\n",
        "    def remove(self):  # 등록된 hook을 제거하는 함수입니다.\n",
        "        self.hook.remove()  # 등록된 hook을 제거합니다.\n"
      ],
      "metadata": {
        "id": "NGkjz2mRLh_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이미지 호출"
      ],
      "metadata": {
        "id": "VOGegMgTLmzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files # 데이터 불러오기\n",
        "file_uploaded=files.upload()   # chap05/data/cat.jpg 데이터 불러오기\n",
        "\n",
        "img=cv2.imread(\"cat.jpg\")\n",
        "plt.imshow(img)\n",
        "img = cv2.resize(img, (100, 100), interpolation=cv2.INTER_LINEAR)  # 이미지 파일, 변경될 이미지 크기, 보간법\n",
        "img = ToTensor()(img).unsqueeze(0)  # 이미지데이터 -> 텐서 -> 인덱스 0에 새로운 차원을 추가 (이 경우에는 배치 차원을 추가)\n",
        "\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "MIVS3psPO93_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conv2d 특성 맵 확인"
      ],
      "metadata": {
        "id": "CuN72ctIPjHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = LayerActivations(model.features, 0)  # 모델의 특성을 가진 모델의 첫 번째 레이어의 활성화 추적기를 생성합니다.\n",
        "                                                # (0번째 Conv2d 레이어의 특성 맵을 확인하기 위해)\n",
        "model(img)  # 모델에 이미지를 전달하여 순전파를 수행합니다.\n",
        "activations = result.features  # 활성화 추적기에서 추출된 특성 맵을 가져옵니다.\n",
        "                                # 이는 0번째 Conv2d 레이어를 통과한 후의 활성화 값입니다."
      ],
      "metadata": {
        "id": "KbV5o898PiCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이 코드는 주어진 이미지를 모델에 전달하고, 특정 레이어의 활성화 값을 추출하는 데 사용됩니다. 먼저, 모델의 첫 번째 레이어에 대한 활성화를 추적하기 위해 LayerActivations 클래스를 사용합니다. 그런 다음, 이미지를 모델에 전달하여 순전파를 수행하고, 지정한 레이어의 활성화 값을 가져옵니다. 이렇게 함으로써 해당 레이어의 특성 맵을 추출할 수 있습니다."
      ],
      "metadata": {
        "id": "74o7wxI1VeYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 특성 맵 시각화"
      ],
      "metadata": {
        "id": "BYi8cAZ9Vg3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(4, 4)  # 4x4 그리드의 하위 그래프를 생성합니다.\n",
        "fig = plt.figure(figsize=(12, 8))  # 그림 크기를 설정합니다.\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)  # 하위 그래프의 간격을 조정합니다.\n",
        "for row in range(4):  # 4개의 행에 대해 반복합니다.\n",
        "    for column in range(4):  # 4개의 열에 대해 반복합니다.\n",
        "        axis = axes[row][column]  # 현재 위치의 축을 가져옵니다.\n",
        "        axis.get_xaxis().set_ticks([])  # x축 눈금을 비활성화합니다.\n",
        "        axis.get_yaxis().set_ticks([])  # y축 눈금을 비활성화합니다.\n",
        "        axis.imshow(activations[0][row*10+column])  # 활성화 특성 맵을 해당 위치에 표시합니다.\n",
        "plt.show()  # 그림을 표시합니다."
      ],
      "metadata": {
        "id": "dw0tM3i5VkVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 20번째 계층에 대한 특성 맵"
      ],
      "metadata": {
        "id": "lXMA1JhsVnym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = LayerActivations(model.features, 20)\n",
        "\n",
        "model(img)\n",
        "activations = result.features"
      ],
      "metadata": {
        "id": "0g9rd_x3VqHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 특성 맵 시각화"
      ],
      "metadata": {
        "id": "0wpEcD9cV6LR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(4,4)\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "for row in range(4):\n",
        "    for column in range(4):\n",
        "        axis = axes[row][column]\n",
        "        axis.get_xaxis().set_ticks([])\n",
        "        axis.get_yaxis().set_ticks([])\n",
        "        axis.imshow(activations[0][row*10+column])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gfBm8cP5VqlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 40번째 계층에 대한 특성 맵"
      ],
      "metadata": {
        "id": "TuXjrLL9WAdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = LayerActivations(model.features, 40)\n",
        "\n",
        "model(img)\n",
        "activations = result.features"
      ],
      "metadata": {
        "id": "FxI6G_KTVsVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 특성 맵 시각화"
      ],
      "metadata": {
        "id": "vzqbhy8YWER0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(4,4)\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "for row in range(4):\n",
        "    for column in range(4):\n",
        "        axis = axes[row][column]\n",
        "        axis.get_xaxis().set_ticks([])\n",
        "        axis.get_yaxis().set_ticks([])\n",
        "        axis.imshow(activations[0][row*10+column])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lF1H_AE8VuNR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}