{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5af567a-8e9e-4cda-9b7f-9111f385f13d",
   "metadata": {},
   "source": [
    "# 10.1.1 희소표현(Sparse Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e63c8e-aa29-417b-9499-262aa950d602",
   "metadata": {},
   "source": [
    "### 원-핫 인코딩 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93e9e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일을 읽어 데이터프레임 생성\n",
    "class2 = pd.read_csv(\"./class2.csv\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 라벨 인코더와 원-핫 인코더 객체 생성\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "# 'class2' 열을 라벨 인코더로 변환하여 train_x에 저장\n",
    "train_x = label_encoder.fit_transform(class2['class2'])\n",
    "\n",
    "# 변환된 결과 출력\n",
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f89b2a-84d7-4c73-879f-98f440431a7e",
   "metadata": {},
   "source": [
    "# 10.1.2 횟수기반 임베딩\n",
    "# Counter Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e30396-b8ea-4630-8042-c4a27474ba3a",
   "metadata": {},
   "source": [
    "### 코퍼스에 카운터 벡터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5298928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 13,\n",
       " 'is': 7,\n",
       " 'last': 8,\n",
       " 'chance': 2,\n",
       " 'and': 0,\n",
       " 'if': 6,\n",
       " 'you': 15,\n",
       " 'do': 3,\n",
       " 'not': 10,\n",
       " 'have': 5,\n",
       " 'will': 14,\n",
       " 'never': 9,\n",
       " 'get': 4,\n",
       " 'any': 1,\n",
       " 'one': 11,\n",
       " 'please': 12}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is last chance.',\n",
    "    'and if you do not have this chance.',\n",
    "    'you will never get any chance.',\n",
    "    'will you do get this one?',\n",
    "    'please, get this chance',\n",
    "]\n",
    "vect = CountVectorizer()\n",
    "# 텍스트 데이터를 벡터 형태로 변환\n",
    "X = vect.fit_transform(corpus)\n",
    "\n",
    "# 각 단어의 인덱스를 담고 있는 딕셔너리 출력\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21666eca-4605-411b-9f0d-b88c43bed86a",
   "metadata": {},
   "source": [
    "### 배열 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda3fe3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(['you will never get any chance.']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bbce08-b992-4a65-9ea1-a8cdf27e3bab",
   "metadata": {},
   "source": [
    "### 불용어를 제거한 카운터 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b305aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last': 6,\n",
       " 'chance': 1,\n",
       " 'if': 5,\n",
       " 'you': 11,\n",
       " 'do': 2,\n",
       " 'not': 8,\n",
       " 'have': 4,\n",
       " 'will': 10,\n",
       " 'never': 7,\n",
       " 'get': 3,\n",
       " 'any': 0,\n",
       " 'one': 9}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"please\", \"this\"]).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5bcaf-6053-4e01-a6aa-316849b82b8c",
   "metadata": {},
   "source": [
    "#TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fea52e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도를 위한 3 x 3 matrix를 만들었습니다.\n",
      "[[1.       0.224325 0.      ]\n",
      " [0.224325 1.       0.      ]\n",
      " [0.       0.       1.      ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 분석할 문서들을 리스트로 정의\n",
    "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
    "\n",
    "# TF-IDF 벡터화를 위한 TfidfVectorizer 객체 생성\n",
    "# min_df=1은 최소 문서 빈도를 1로 설정하여 모든 단어를 포함함\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
    "\n",
    "# 문서를 TF-IDF 벡터로 변환\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
    "\n",
    "# TF-IDF 행렬을 전치하여 문서 간 유사도 계산\n",
    "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
    "\n",
    "# 유사도를 위한 행렬의 크기 출력\n",
    "print ('유사도를 위한', str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), 'matrix를 만들었습니다.')\n",
    "\n",
    "# 문서 간 유사도 행렬 출력\n",
    "print(doc_distance.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6c8d4-dafa-4f42-9bc6-eb55a45fca3c",
   "metadata": {},
   "source": [
    "# 10.1.3 예측기반 임베딩\n",
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d838a8b-4bf4-47a7-8d2c-162db93deb30",
   "metadata": {},
   "source": [
    "### 데이터셋을 메모리로 로딩하고 토큰화 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d68eed27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['once',\n",
       "  'upon',\n",
       "  'a',\n",
       "  'time',\n",
       "  'in',\n",
       "  'london',\n",
       "  ',',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'went',\n",
       "  'out',\n",
       "  'to',\n",
       "  'a',\n",
       "  'dinner',\n",
       "  'party',\n",
       "  'leaving',\n",
       "  'their',\n",
       "  'three',\n",
       "  'children',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'at',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'wendy',\n",
       "  'had',\n",
       "  'tucked',\n",
       "  'her',\n",
       "  'younger',\n",
       "  'brothers',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'to',\n",
       "  'bed',\n",
       "  ',',\n",
       "  'she',\n",
       "  'went',\n",
       "  'to',\n",
       "  'read',\n",
       "  'a',\n",
       "  'book',\n",
       "  '.'],\n",
       " ['she', 'heard', 'a', 'boy', 'sobbing', 'outside', 'her', 'window', '.'],\n",
       " ['he', 'was', 'flying', '.'],\n",
       " ['there', 'was', 'little', 'fairy', 'fluttering', 'around', 'him', '.'],\n",
       " ['wendy', 'opened', 'the', 'window', 'to', 'talk', 'to', 'him', '.'],\n",
       " ['“', 'hello', '!'],\n",
       " ['who', 'are', 'you', '?'],\n",
       " ['why', 'are', 'you', 'crying', '”', ',', 'wendy', 'asked', 'him', '.'],\n",
       " ['“', 'my', 'name', 'is', 'peter', 'pan', '.'],\n",
       " ['my',\n",
       "  'shadow',\n",
       "  'wouldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'me.',\n",
       "  '”',\n",
       "  ',',\n",
       "  'he',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['she', 'asked', 'him', 'to', 'come', 'in', '.'],\n",
       " ['peter', 'agreed', 'and', 'came', 'inside', 'the', 'room', '.'],\n",
       " ['wendy',\n",
       "  'took',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'and',\n",
       "  'sewed',\n",
       "  'it',\n",
       "  'to',\n",
       "  'his',\n",
       "  'shoe',\n",
       "  'tips',\n",
       "  '.'],\n",
       " ['now',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'followed',\n",
       "  'him',\n",
       "  'wherever',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'went',\n",
       "  '!'],\n",
       " ['he',\n",
       "  'was',\n",
       "  'delighted',\n",
       "  'and',\n",
       "  'asked',\n",
       "  'wendy',\n",
       "  '“',\n",
       "  'why',\n",
       "  'don',\n",
       "  '’',\n",
       "  't',\n",
       "  'you',\n",
       "  'come',\n",
       "  'with',\n",
       "  'me',\n",
       "  'to',\n",
       "  'my',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['the', 'neverland', '.'],\n",
       " ['i',\n",
       "  'lived',\n",
       "  'there',\n",
       "  'with',\n",
       "  'my',\n",
       "  'fairy',\n",
       "  'tinker',\n",
       "  'bell.',\n",
       "  '”',\n",
       "  'wendy',\n",
       "  '?'],\n",
       " ['“', 'oh', '!'],\n",
       " ['what', 'a', 'wonderful', 'idea', '!'],\n",
       " ['let', 'me', 'wake', 'up', 'john', 'and', 'micheal', 'too', '.'],\n",
       " ['could', 'you', 'teach', 'us', 'how', 'to', 'fly', '?', '”', '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['of', 'course', '!'],\n",
       " ['get',\n",
       "  'them',\n",
       "  'we',\n",
       "  'will',\n",
       "  'all',\n",
       "  'fly',\n",
       "  'together.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'replied',\n",
       "  'and',\n",
       "  'so',\n",
       "  'it',\n",
       "  'was',\n",
       "  '.'],\n",
       " ['five',\n",
       "  'little',\n",
       "  'figures',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'of',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'and',\n",
       "  'headed',\n",
       "  'towards',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'they',\n",
       "  'flew',\n",
       "  'over',\n",
       "  'the',\n",
       "  'island',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'told',\n",
       "  'the',\n",
       "  'children',\n",
       "  'more',\n",
       "  'about',\n",
       "  'his',\n",
       "  'homeland',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'who',\n",
       "  'get',\n",
       "  'lost',\n",
       "  'come',\n",
       "  'and',\n",
       "  'stay',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'and',\n",
       "  'me',\n",
       "  ',',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['the', 'indians', 'also', 'live', 'in', 'neverland', '.'],\n",
       " ['the',\n",
       "  'mermaids',\n",
       "  'live',\n",
       "  'in',\n",
       "  'the',\n",
       "  'lagoon',\n",
       "  'around',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['and',\n",
       "  'a',\n",
       "  'very',\n",
       "  'mean',\n",
       "  'pirate',\n",
       "  'called',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'keeps',\n",
       "  'troubling',\n",
       "  'everyone',\n",
       "  '.'],\n",
       " ['“', 'crocodile', 'bit', 'his', 'one', 'arm', '.'],\n",
       " ['so',\n",
       "  'the',\n",
       "  'captain',\n",
       "  'had',\n",
       "  'to',\n",
       "  'put',\n",
       "  'a',\n",
       "  'hook',\n",
       "  'in',\n",
       "  'its',\n",
       "  'place',\n",
       "  '.'],\n",
       " ['since', 'then', 'he', 'is', 'afraid', 'of', 'crocodiles', '.'],\n",
       " ['and', 'rightly', 'so', '!'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'ever',\n",
       "  'found',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'it',\n",
       "  'will',\n",
       "  'eat',\n",
       "  'up',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'it',\n",
       "  'couldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'eat',\n",
       "  'last',\n",
       "  'time.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['soon', 'they', 'landed', 'on', 'the', 'island', '.'],\n",
       " ['and',\n",
       "  'to',\n",
       "  'the',\n",
       "  'surprise',\n",
       "  'of',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'let',\n",
       "  'them',\n",
       "  'in',\n",
       "  'through',\n",
       "  'a',\n",
       "  'small',\n",
       "  'opening',\n",
       "  'in',\n",
       "  'a',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['inside',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'was',\n",
       "  'a',\n",
       "  'large',\n",
       "  'room',\n",
       "  'with',\n",
       "  'children',\n",
       "  'inside',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['somewhere',\n",
       "  'huddled',\n",
       "  'by',\n",
       "  'the',\n",
       "  'fire',\n",
       "  'in',\n",
       "  'the',\n",
       "  'corner',\n",
       "  'and',\n",
       "  'somewhere',\n",
       "  'playing',\n",
       "  'amongst',\n",
       "  'themselves',\n",
       "  '.'],\n",
       " ['their',\n",
       "  'faces',\n",
       "  'lit',\n",
       "  'up',\n",
       "  'when',\n",
       "  'they',\n",
       "  'saw',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  ',',\n",
       "  'and',\n",
       "  'their',\n",
       "  'guests',\n",
       "  '.'],\n",
       " ['“', 'hello', 'everyone', '.'],\n",
       " ['this', 'is', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['they',\n",
       "  'will',\n",
       "  'be',\n",
       "  'staying',\n",
       "  'with',\n",
       "  'us',\n",
       "  'from',\n",
       "  'now',\n",
       "  'on.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'introduced',\n",
       "  'them',\n",
       "  'to',\n",
       "  'all',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['children', 'welcomed', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['a', 'few', 'days', 'passed', '.'],\n",
       " ['and', 'they', 'settled', 'into', 'a', 'routine', '.'],\n",
       " ['wendy',\n",
       "  'would',\n",
       "  'take',\n",
       "  'care',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'in',\n",
       "  'the',\n",
       "  'day',\n",
       "  'and',\n",
       "  'would',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brothers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'evening',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'would',\n",
       "  'cook',\n",
       "  'for',\n",
       "  'them',\n",
       "  'and',\n",
       "  'stitch',\n",
       "  'new',\n",
       "  'clothes',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'even',\n",
       "  'made',\n",
       "  'a',\n",
       "  'lovely',\n",
       "  'new',\n",
       "  'dress',\n",
       "  'for',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  '.'],\n",
       " ['one',\n",
       "  'evening',\n",
       "  ',',\n",
       "  'as',\n",
       "  'they',\n",
       "  'were',\n",
       "  'out',\n",
       "  'exploring',\n",
       "  'the',\n",
       "  'island',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'warned',\n",
       "  'everyone',\n",
       "  'and',\n",
       "  'said',\n",
       "  ',',\n",
       "  '“',\n",
       "  'hide',\n",
       "  '!'],\n",
       " ['hide', '!'],\n",
       " ['pirates', '!'],\n",
       " ['and',\n",
       "  'they',\n",
       "  'have',\n",
       "  'kidnapped',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'princess',\n",
       "  'tiger',\n",
       "  'lily',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'have',\n",
       "  'kept',\n",
       "  'her',\n",
       "  'there',\n",
       "  ',',\n",
       "  'tied',\n",
       "  'up',\n",
       "  'by',\n",
       "  'the',\n",
       "  'rocks',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'was',\n",
       "  'afraid',\n",
       "  'and',\n",
       "  'the',\n",
       "  'princess',\n",
       "  'would',\n",
       "  'drown',\n",
       "  ',',\n",
       "  'is',\n",
       "  'she',\n",
       "  'fell',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  '.'],\n",
       " ['so',\n",
       "  ',',\n",
       "  'in',\n",
       "  'a',\n",
       "  'voice',\n",
       "  'that',\n",
       "  'sounded',\n",
       "  'like',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  ',',\n",
       "  'he',\n",
       "  'shouted',\n",
       "  'instructions',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'guarded',\n",
       "  'her',\n",
       "  ',',\n",
       "  '“',\n",
       "  'you',\n",
       "  'fools',\n",
       "  '!'],\n",
       " ['let', 'her', 'go', 'at', 'once', '!'],\n",
       " ['do',\n",
       "  'it',\n",
       "  'before',\n",
       "  'i',\n",
       "  'come',\n",
       "  'there',\n",
       "  'or',\n",
       "  'else',\n",
       "  'i',\n",
       "  'will',\n",
       "  'throw',\n",
       "  'each',\n",
       "  'one',\n",
       "  'of',\n",
       "  'you',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'got',\n",
       "  'scared',\n",
       "  'and',\n",
       "  'immediately',\n",
       "  'released',\n",
       "  'the',\n",
       "  'princes',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'quickly',\n",
       "  'dived',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  'and',\n",
       "  'swam',\n",
       "  'to',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'her',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['soon',\n",
       "  'everyone',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'had',\n",
       "  'rescued',\n",
       "  'the',\n",
       "  'princess',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'had',\n",
       "  'tricked',\n",
       "  'his',\n",
       "  'men',\n",
       "  'he',\n",
       "  'was',\n",
       "  'furious',\n",
       "  '.'],\n",
       " ['and', 'swore', 'to', 'have', 'his', 'revenge', '.'],\n",
       " ['that',\n",
       "  'night',\n",
       "  'wendy',\n",
       "  'told',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'that',\n",
       "  'she',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brother',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'go',\n",
       "  'back',\n",
       "  'home',\n",
       "  'since',\n",
       "  'they',\n",
       "  'missed',\n",
       "  'their',\n",
       "  'parents',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'said',\n",
       "  'if',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'could',\n",
       "  'also',\n",
       "  'return',\n",
       "  'to',\n",
       "  'her',\n",
       "  'world',\n",
       "  'they',\n",
       "  'could',\n",
       "  'find',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'home',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['peter', 'pan', 'didn', '’', 't', 'want', 'to', 'leave', 'neverland', '.'],\n",
       " ['but',\n",
       "  'the',\n",
       "  'sake',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'he',\n",
       "  'agreed',\n",
       "  ',',\n",
       "  'although',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'sadly',\n",
       "  '.'],\n",
       " ['he', 'would', 'miss', 'his', 'friends', 'dearly', '.'],\n",
       " ['the',\n",
       "  'next',\n",
       "  'morning',\n",
       "  'all',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'left',\n",
       "  'with',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'on',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'and',\n",
       "  'his',\n",
       "  'men',\n",
       "  'kidnapped',\n",
       "  'all',\n",
       "  'of',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'tied',\n",
       "  'them',\n",
       "  'and',\n",
       "  'kept',\n",
       "  'them',\n",
       "  'on',\n",
       "  'once',\n",
       "  'of',\n",
       "  'his',\n",
       "  'ships',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'peter',\n",
       "  'found',\n",
       "  'out',\n",
       "  'about',\n",
       "  'it',\n",
       "  'he',\n",
       "  'rushed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ship',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'himself',\n",
       "  'from',\n",
       "  'a',\n",
       "  'tress',\n",
       "  'branch',\n",
       "  'and',\n",
       "  'on',\n",
       "  'to',\n",
       "  'the',\n",
       "  'deck',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ship',\n",
       "  'where',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'were',\n",
       "  'tied',\n",
       "  'up',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'bravely',\n",
       "  'and',\n",
       "  'threw',\n",
       "  'over',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'him',\n",
       "  '.'],\n",
       " ['quickly',\n",
       "  'he',\n",
       "  'released',\n",
       "  'everyone',\n",
       "  'from',\n",
       "  'their',\n",
       "  'captor',\n",
       "  '’',\n",
       "  's',\n",
       "  'ties',\n",
       "  '.'],\n",
       " ['wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'michael',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'helped',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  ',',\n",
       "  'where',\n",
       "  'their',\n",
       "  'friends',\n",
       "  'from',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'camp',\n",
       "  'were',\n",
       "  'ready',\n",
       "  'with',\n",
       "  'smaller',\n",
       "  'boats',\n",
       "  'to',\n",
       "  'take',\n",
       "  'them',\n",
       "  'to',\n",
       "  'safety',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'now',\n",
       "  'went',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'let',\n",
       "  'us',\n",
       "  'finished',\n",
       "  'this',\n",
       "  'forever',\n",
       "  'mr.',\n",
       "  'hook',\n",
       "  '”',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'challenged',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'you',\n",
       "  'have',\n",
       "  'caused',\n",
       "  'me',\n",
       "  'enough',\n",
       "  'trouble',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'time',\n",
       "  'that',\n",
       "  'we',\n",
       "  'finished',\n",
       "  'this.',\n",
       "  '”',\n",
       "  'hook',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['with',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'drawn',\n",
       "  ',',\n",
       "  'he',\n",
       "  'raced',\n",
       "  'towards',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  '.'],\n",
       " ['quick',\n",
       "  'on',\n",
       "  'his',\n",
       "  'feet',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'stepped',\n",
       "  'aside',\n",
       "  'and',\n",
       "  'pushed',\n",
       "  'hook',\n",
       "  'inside',\n",
       "  'the',\n",
       "  'sea',\n",
       "  'where',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'was',\n",
       "  'waiting',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'rejoiced',\n",
       "  'as',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'was',\n",
       "  'out',\n",
       "  'of',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'forever',\n",
       "  '.'],\n",
       " ['everybody', 'headed', 'back', 'to', 'london', '.'],\n",
       " ['mr.', 'and', 'mrs', '.'],\n",
       " ['darling',\n",
       "  'was',\n",
       "  'so',\n",
       "  'happy',\n",
       "  'to',\n",
       "  'see',\n",
       "  'their',\n",
       "  'children',\n",
       "  'and',\n",
       "  'they',\n",
       "  'agreed',\n",
       "  'to',\n",
       "  'adopt',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'even',\n",
       "  'asked',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'to',\n",
       "  'come',\n",
       "  'and',\n",
       "  'live',\n",
       "  'with',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'said',\n",
       "  ',',\n",
       "  'he',\n",
       "  'never',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'up',\n",
       "  ',',\n",
       "  'so',\n",
       "  'he',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'will',\n",
       "  'go',\n",
       "  'back',\n",
       "  'to',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  'promised',\n",
       "  'everyone',\n",
       "  'that',\n",
       "  'he',\n",
       "  'will',\n",
       "  'visit',\n",
       "  'again',\n",
       "  'sometime',\n",
       "  '!'],\n",
       " ['and',\n",
       "  'he',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'by',\n",
       "  'his',\n",
       "  'side',\n",
       "  '.']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "  \n",
    "sample = open(\"./peter.txt\", \"r\", encoding='UTF8') # 피터팬 데이터셋 로딩\n",
    "s = sample.read() \n",
    "  \n",
    "f = s.replace(\"\\n\", \" \") # 줄바꿈을 공백으로 변환\n",
    "data = [] \n",
    "  \n",
    "for i in sent_tokenize(f): # 로딩한 파일의 각 문장마다 반복\n",
    "    temp = [] \n",
    "    for j in word_tokenize(i): # 문장을 단어로 토큰화\n",
    "        temp.append(j.lower()) # 토큰화된 단어를 소문자로 변환하여 temp에 저장\n",
    "    data.append(temp) \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75c45c-e1af-4c10-9b7d-6566eb2b346a",
   "metadata": {},
   "source": [
    "#CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a64a3-e510-452d-b3b0-2a150261a858",
   "metadata": {},
   "source": [
    "### 데이터셋에 CBOW 적용 후 'peter'와 'wendy'의 유사성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcbd3aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' wendy' - CBOW :  0.074393824\n"
     ]
    }
   ],
   "source": [
    "model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
    "                              vector_size = 100, window = 5, sg=0) # sg 0:CBOW, 1:skip-gram\n",
    "print(\"Cosine similarity between 'peter' \" + \"wendy' - CBOW : \", \n",
    "      model1.wv.similarity('peter', 'wendy')) # 결과 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d86c6-e846-4c50-b259-b169d7170c45",
   "metadata": {},
   "source": [
    "### 'peter'와 'hook'의 유사성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6eac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' hook' - CBOW :  0.02770986\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'peter' \" +\n",
    "                 \"hook' - CBOW : \", \n",
    "      model1.wv.similarity('peter', 'hook')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45edc87d-2f1d-499b-b76c-3696d82fd22f",
   "metadata": {},
   "source": [
    "#Skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d52068-e48b-4454-a614-3c3101033e36",
   "metadata": {},
   "source": [
    "### 데이터셋에 skip-gram 적용 후 'peter'와 'wendy'의 유사성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb8edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' wendy' - Skip Gram :  0.4008868\n"
     ]
    }
   ],
   "source": [
    "model2 = gensim.models.Word2Vec(data, min_count = 1, vector_size = 100, \n",
    "                                             window = 5, sg = 1) # skip-gram 모델 사용\n",
    "print(\"Cosine similarity between 'peter' \" +\n",
    "          \"wendy' - Skip Gram : \", \n",
    "    model2.wv.similarity('peter', 'wendy')) # 결과 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e34142-ce2f-469e-b573-5dc327be4c22",
   "metadata": {},
   "source": [
    "### 'peter'와 'hook'의 유사성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8128bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' hook' - Skip Gram :  0.52016735\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'peter' \" +\n",
    "            \"hook' - Skip Gram : \", \n",
    "      model2.wv.similarity('peter', 'hook')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a42bb-031c-463a-a61d-af46392a6f0d",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9afd47-1484-4fef-969d-670f088648d8",
   "metadata": {},
   "source": [
    "### 라이브러리 및 데이터 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20a1b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText('./peter.txt', vector_size=4, window=3, min_count=1, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528985ad-6335-49a9-bde7-e181b6c6f560",
   "metadata": {},
   "source": [
    "### 'peter', 'wendy'에 대한 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "216300d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4592452\n"
     ]
    }
   ],
   "source": [
    "sim_score = model.wv.similarity('peter', 'wendy')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191e6a84-efb1-4a07-aa52-cb2a5ce163be",
   "metadata": {},
   "source": [
    "### 'peter', 'hook'에 대한 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8afd9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043825187\n"
     ]
    }
   ],
   "source": [
    "sim_score = model.wv.similarity('peter', 'hook')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352d2b8-ffce-4375-8a44-cd3896a2d04b",
   "metadata": {},
   "source": [
    "# 사전 훈련된 패스트텍스트 모델 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce9220-db73-4b8d-a5b4-b09c02808180",
   "metadata": {},
   "source": [
    "### 라이브러리와 사전 훈련된 모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4543f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors # gensim은 자연어를 벡터로 변환하는 데 필요한 편의 기능을 제공하는 라이브러리\n",
    "\n",
    "model_kr = KeyedVectors.load_word2vec_format('./wiki.ko.vec') # 파일을 메모리로 불러온다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ae47d-eedc-41c3-8575-3ebd5fcbbd8f",
   "metadata": {},
   "source": [
    "### '노력'과 유사한 단어와 유사도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5fb5c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 노력함, Similarity: 0.80\n",
      "Word: 노력중, Similarity: 0.75\n",
      "Word: 노력만, Similarity: 0.72\n",
      "Word: 노력과, Similarity: 0.71\n",
      "Word: 노력의, Similarity: 0.69\n",
      "Word: 노력가, Similarity: 0.69\n",
      "Word: 노력이나, Similarity: 0.69\n",
      "Word: 노력없이, Similarity: 0.68\n",
      "Word: 노력맨, Similarity: 0.68\n",
      "Word: 노력보다는, Similarity: 0.68\n"
     ]
    }
   ],
   "source": [
    "find_similar_to = '노력'\n",
    "\n",
    "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7db87-ca08-4bee-8fca-676d4ba6da19",
   "metadata": {},
   "source": [
    "### '동물', '육식동물'에는 긍정적이지만 '사람'에는 부정적인 단어와 유사도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346acbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('초식동물', 0.7804121971130371), ('거대동물', 0.7547270059585571), ('육식동물의', 0.7547166347503662), ('유두동물', 0.753511369228363), ('반추동물', 0.7470757961273193), ('독동물', 0.7466291785240173), ('육상동물', 0.7460315823554993), ('유즐동물', 0.7450904250144958), ('극피동물', 0.7449344396591187), ('복모동물', 0.742434561252594)]\n"
     ]
    }
   ],
   "source": [
    "similarities = model_kr.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f813ff-cce7-4661-8f33-4e8bfa79aac0",
   "metadata": {},
   "source": [
    "# 10.1.4 횟수/예측기반 임베딩\n",
    "# GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f2243b-9d01-417e-b669-f6d4ea0e69ab",
   "metadata": {},
   "source": [
    "### 라이브러리 호출 및 데이터셋 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5752236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# 'glove.6B.100d.txt' 파일의 경로를 얻습니다.\n",
    "glove_file = datapath('glove.6B.100d.txt') \n",
    "\n",
    "# 임시 파일의 경로를 얻습니다. 변환된 Word2Vec 포맷의 GloVe 파일이 저장될 위치입니다.\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
    "\n",
    "# GloVe 파일을 Word2Vec 포맷으로 변환합니다.\n",
    "glove2word2vec(glove_file, word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c65d8e6-1148-4828-ac8f-ed981445e544",
   "metadata": {},
   "source": [
    "### 'bill'과 유사한 단어의 리스트를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3db496ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('legislation', 0.8072139620780945),\n",
       " ('proposal', 0.7306863069534302),\n",
       " ('senate', 0.7142541408538818),\n",
       " ('bills', 0.704440176486969),\n",
       " ('measure', 0.6958035230636597),\n",
       " ('passed', 0.6906244158744812),\n",
       " ('amendment', 0.6846879720687866),\n",
       " ('provision', 0.6845567226409912),\n",
       " ('plan', 0.6816462874412537),\n",
       " ('clinton', 0.6663140654563904)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_glove_file) # word2vec.c 형식으로 벡터를 가져온다\n",
    "model.most_similar('bill') # 'bill'을 기준으로 가장 유사한 단어들의 리스트를 보여 준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57d14331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('peach', 0.688809871673584),\n",
       " ('mango', 0.683819055557251),\n",
       " ('plum', 0.6684104204177856),\n",
       " ('berry', 0.659035861492157),\n",
       " ('grove', 0.6581551432609558),\n",
       " ('blossom', 0.6503506302833557),\n",
       " ('raspberry', 0.6477391719818115),\n",
       " ('strawberry', 0.6442098021507263),\n",
       " ('pine', 0.6390928626060486),\n",
       " ('almond', 0.6379212737083435)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('cherry') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c609124b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kazushige', 0.48343509435653687),\n",
       " ('askerov', 0.4778185784816742),\n",
       " ('lakpa', 0.46915262937545776),\n",
       " ('ex-gay', 0.45713329315185547),\n",
       " ('tadayoshi', 0.4522106647491455),\n",
       " ('turani', 0.4481006860733032),\n",
       " ('saglam', 0.4469599425792694),\n",
       " ('aijun', 0.4435270130634308),\n",
       " ('adjustors', 0.44235295057296753),\n",
       " ('nyum', 0.4423118233680725)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative='cherry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21c9f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.7699\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392152e-f108-4bc1-8748-ecebc8198edc",
   "metadata": {},
   "source": [
    "### 'australia', 'beer', 'france'와 관련성이 있는 단어를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72881522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'champagne'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]\n",
    "analogy('australia', 'beer', 'france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a8a76cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'longest'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('tall', 'tallest', 'long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "820bf3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0e946-8f96-490c-b3e3-a8e0a59b65cf",
   "metadata": {},
   "source": [
    "# 10.2 Transformer attention\n",
    "# 10.2.1 Seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aac8dd-be49-4e29-9ca8-e56742002f47",
   "metadata": {},
   "source": [
    "### 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ae5b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division # __future__ : 구 버전에서 상위 버전을 이용할 때 사용\n",
    "                                                                  # 최신 버전의 파이토치를 사용하는 경우에는 필요하지 않다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re # 정규표현식을 사용하고자 할 때 사용\n",
    "          # 정규표현식 : 특정한 규칙을 갖는 문자열의 집합을 표현하기 위한 형식\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3775b-487c-4f52-9e92-a163f6d4561a",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4841b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "class Lang: # 딕셔너리를 만들기 위한 클래스\n",
    "    def __init__(self): # 단어의 인덱스를 저장하기 위한 컨테이너를 초기화\n",
    "        self.word2index = {}  # 단어를 인덱스로 매핑하는 딕셔너리\n",
    "        self.word2count = {}  # 단어의 빈도를 저장하는 딕셔너리\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}  # 인덱스를 단어로 매핑하는 딕셔너리\n",
    "                                                # SOS(Start Of Sequence) : 문장의 시작\n",
    "                                                # EOS(End Of Sequence) : 문장의 끝\n",
    "        self.n_words = 2  # SOS와 EOS에 대한 카운트\n",
    "\n",
    "    # 문장을 단어 단위로 분리한 후 컨테이너(word)에 추가\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):  # 문장을 단어 단위로 분할\n",
    "            self.addWord(word)  # 각 단어를 단어 사전에 추가\n",
    "\n",
    "    # 컨테이너에 단어가 없다면 추가되고, 있다면 카운트를 업데이트\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:  # 단어가 아직 단어 사전에 없으면\n",
    "            self.word2index[word] = self.n_words  # 단어에 새로운 인덱스 할당\n",
    "            self.word2count[word] = 1  # 단어 빈도를 1로 설정\n",
    "            self.index2word[self.n_words] = word  # 새로운 단어를 인덱스에 매핑\n",
    "            self.n_words += 1  # 단어 수 증가\n",
    "        else:  # 단어가 이미 단어 사전에 있으면\n",
    "            self.word2count[word] += 1  # 단어 빈도를 증가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6b442-f54d-4e82-b9f0-97b4465b864b",
   "metadata": {},
   "source": [
    "### 데이터 정규화\n",
    "- 데이터셋은 영어와 프랑스어가 탭으로 구성된 text 파일이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58ebe3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 문자열을 정규화하는 함수\n",
    "def normalizeString(df, lang):\n",
    "    # 소문자로 변환\n",
    "    sentence = df[lang].str.lower()\n",
    "    # 알파벳과 공백을 제외한 모든 문자를 제거\n",
    "    sentence = sentence.str.replace('[^A-Za-z\\s]+', ' ')\n",
    "    # 유니코드 정규화를 통해 문자를 분해\n",
    "    sentence = sentence.str.normalize('NFD')\n",
    "    # ASCII로 인코딩한 후 디코딩하여 발음 구별 기호를 제거 (Unicode -> ASCII)\n",
    "    sentence = sentence.str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    return sentence\n",
    "\n",
    "# 두 언어의 문장을 정규화하여 반환하는 함수\n",
    "def read_sentence(df, lang1, lang2):\n",
    "    # 첫 번째 언어의 문장을 정규화\n",
    "    sentence1 = normalizeString(df, lang1)\n",
    "    # 두 번째 언어의 문장을 정규화\n",
    "    sentence2 = normalizeString(df, lang2)\n",
    "    return sentence1, sentence2\n",
    "\n",
    "# 파일을 읽어 데이터프레임으로 반환하는 함수\n",
    "def read_file(loc, lang1, lang2):\n",
    "    # 파일을 읽어 데이터프레임 생성 (탭으로 구분, 헤더 없음)\n",
    "    df = pd.read_csv(loc, delimiter='\\t', header=None, names=[lang1, lang2])\n",
    "    return df\n",
    "\n",
    "# 데이터를 처리하는 함수\n",
    "def process_data(lang1, lang2):\n",
    "    # 파일을 읽어 데이터프레임으로 변환\n",
    "    df = read_file('./%s-%s.txt' % (lang1, lang2), lang1, lang2)\n",
    "    # 두 언어의 문장을 정규화\n",
    "    sentence1, sentence2 = read_sentence(df, lang1, lang2)\n",
    "\n",
    "    # 입력 언어와 출력 언어를 위한 Lang 객체 생성\n",
    "    input_lang = Lang()\n",
    "    output_lang = Lang()\n",
    "    pairs = []\n",
    "\n",
    "    # 데이터프레임의 각 행을 순회\n",
    "    for i in range(len(df)):\n",
    "        # 문장의 길이가 최대 길이보다 작은 경우에만 처리\n",
    "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
    "            # 한 쌍의 문장 생성\n",
    "            full = [sentence1[i], sentence2[i]]\n",
    "            # 입력 언어와 출력 언어 사전에 문장 추가\n",
    "            input_lang.addSentence(sentence1[i])\n",
    "            output_lang.addSentence(sentence2[i])\n",
    "            # 쌍을 pairs 리스트에 추가\n",
    "            pairs.append(full)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe5ab6-b53c-461f-962c-45fa906546b1",
   "metadata": {},
   "source": [
    "### 텐서로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c3e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    # 문장에서 각 단어를 인덱스로 변환\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    # 문장을 텐서로 변환\n",
    "    indexes = indexesFromSentence(lang, sentence)  # 문장을 단어 인덱스의 리스트로 변환\n",
    "    indexes.append(EOS_token)  # 문장의 끝을 나타내는 EOS 토큰 추가\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)  # 인덱스 리스트를 텐서로 변환하고 열 벡터로 변환\n",
    "\n",
    "def tensorsFromPair(input_lang, output_lang, pair):\n",
    "    # 입력 언어와 출력 언어의 문장 쌍을 텐서 쌍으로 변환\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])  # 입력 문장을 텐서로 변환\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])  # 출력 문장을 텐서로 변환\n",
    "    return (input_tensor, target_tensor)  # 입력 텐서와 출력 텐서를 쌍으로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d0190-e90c-439f-9677-295ba91000d7",
   "metadata": {},
   "source": [
    "### 인코더 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5cda608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super(Encoder, self).__init__()       \n",
    "        self.input_dim = input_dim  # 입력 차원 크기\n",
    "        self.embbed_dim = embbed_dim  # 임베딩 차원 크기\n",
    "        self.hidden_dim = hidden_dim  # 은닉 상태 차원 크기\n",
    "        self.num_layers = num_layers  # GRU 레이어 수\n",
    "        self.embedding = nn.Embedding(input_dim, self.embbed_dim)  # 임베딩 레이어 정의\n",
    "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)  # GRU 레이어 정의\n",
    "              \n",
    "    def forward(self, src):      \n",
    "        embedded = self.embedding(src).view(1,1,-1)  # 입력을 임베딩하고 크기를 조정\n",
    "        outputs, hidden = self.gru(embedded)  # 임베딩된 입력을 GRU에 통과시킴\n",
    "        return outputs, hidden  # GRU의 출력과 은닉 상태를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572b891-0da8-4428-96c2-d3ada374ddb4",
   "metadata": {},
   "source": [
    "### 디코더 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c8c263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embbed_dim = embbed_dim  # 임베딩 차원 크기\n",
    "        self.hidden_dim = hidden_dim  # 은닉 상태 차원 크기\n",
    "        self.output_dim = output_dim  # 출력 차원 크기\n",
    "        self.num_layers = num_layers  # GRU 레이어 수\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, self.embbed_dim)  # 임베딩 레이어 정의\n",
    "        self.gru = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)  # GRU 레이어 정의\n",
    "        self.out = nn.Linear(self.hidden_dim, output_dim)  # 선형 변환 레이어 정의\n",
    "        self.softmax = nn.LogSoftmax(dim=1)  # 소프트맥스 레이어 정의\n",
    "      \n",
    "    def forward(self, input, hidden):\n",
    "        input = input.view(1, -1)  # 입력의 크기를 조정\n",
    "        embedded = F.relu(self.embedding(input))  # 입력을 임베딩하고 ReLU 활성화 함수를 적용\n",
    "        output, hidden = self.gru(embedded, hidden)  # 임베딩된 입력과 이전 은닉 상태를 GRU에 통과시킴\n",
    "        prediction = self.softmax(self.out(output[0]))  # GRU의 출력을 선형 변환하고 소프트맥스를 적용하여 예측값을 얻음\n",
    "        return prediction, hidden  # 예측값과 은닉 상태를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf64ab0-638f-4851-9023-dbaa62b09578",
   "metadata": {},
   "source": [
    "### seq2seq 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e32442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "      \n",
    "        self.encoder = encoder  # 인코더를 초기화\n",
    "        self.decoder = decoder  # 디코더를 초기화\n",
    "        self.device = device  # 사용할 장치 (CPU 또는 GPU)를 설정\n",
    "     \n",
    "    def forward(self, input_lang, output_lang, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        input_length = input_lang.size(0)  # 입력 문장의 길이\n",
    "        batch_size = output_lang.shape[1]  # 배치 크기\n",
    "        target_length = output_lang.shape[0]  # 출력 문장의 길이\n",
    "        vocab_size = self.decoder.output_dim  # 디코더의 출력 차원 크기 (어휘 크기)\n",
    "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)  # 출력 텐서를 초기화\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(input_lang[i])  # 인코더에 입력 문장의 각 단어를 통과시킴\n",
    "\n",
    "        decoder_hidden = encoder_hidden.to(device)  # 인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로 설정\n",
    "        decoder_input = torch.tensor([SOS_token], device=device)  # 디코더의 초기 입력을 SOS 토큰으로 설정\n",
    "\n",
    "        for t in range(target_length):   \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)  # 디코더에 입력을 통과시켜 출력과 새로운 은닉 상태를 얻음\n",
    "            outputs[t] = decoder_output  # 디코더의 출력을 저장\n",
    "            teacher_force = random.random() < teacher_forcing_ratio  # 티처포스(교사 강요)\n",
    "            topv, topi = decoder_output.topk(1)  # 디코더 출력의 최상위 값을 얻음\n",
    "            input = (output_lang[t] if teacher_force else topi)  # 교사 강요에 따라 다음 입력을 설정 (실제 타겟 시퀀스 값)\n",
    "            if(teacher_force == False and input.item() == EOS_token):  # 교사 강요가 아니고 EOS 토큰이 나오면 중단\n",
    "                break\n",
    "        return outputs  # 출력 텐서를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9565c-7a8c-4918-8801-28d4a85493c8",
   "metadata": {},
   "source": [
    "### 모델의 오차 계산 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93d4ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5  # teacher forcing 비율을 0.5로 설정\n",
    "\n",
    "def Model(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
    "    model_optimizer.zero_grad()  # 모델 옵티마이저의 기울기를 0으로 초기화\n",
    "    input_length = input_tensor.size(0)  # 입력 텐서의 길이를 설정\n",
    "    loss = 0  # 손실값을 0으로 초기화\n",
    "    epoch_loss = 0  # 에포크 손실값을 0으로 초기화\n",
    "    output = model(input_tensor, target_tensor)  # 모델에 입력 텐서와 타겟 텐서를 전달하여 출력 계산\n",
    "    num_iter = output.size(0)  # 출력의 길이를 설정\n",
    "\n",
    "    for ot in range(num_iter):  # 출력의 각 타임스텝마다\n",
    "        loss += criterion(output[ot], target_tensor[ot])  # 타임스텝별 손실을 계산하고 누적\n",
    "                                                          # 모델의 예측 결과와 정답을 이용\n",
    "\n",
    "    loss.backward()  # 역전파를 통해 기울기 계산\n",
    "    model_optimizer.step()  # 모델 옵티마이저를 통해 모델 파라미터 업데이트\n",
    "    epoch_loss = loss.item() / num_iter  # 에포크 손실값을 타임스텝 수로 나누어 평균 손실값 계산\n",
    "    return epoch_loss  # 에포크 손실값 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f51e72-3182-460f-927f-5e9127f2ee4c",
   "metadata": {},
   "source": [
    "### 모델 훈련 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9768b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, input_lang, output_lang, pairs, num_iteration=20000):\n",
    "    model.train()  # 모델을 학습 모드로 전환\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)  # 옵티마이저로 SGD를 설정하고 학습률을 0.01로 설정\n",
    "    criterion = nn.NLLLoss()  # 손실 함수로 NLLLoss를 사용\n",
    "    total_loss_iterations = 0  # 총 손실값을 0으로 초기화\n",
    "\n",
    "    # 학습 쌍을 생성하여 리스트에 저장\n",
    "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs)) \n",
    "                      for i in range(num_iteration)]\n",
    "  \n",
    "    # 지정된 반복 횟수만큼 학습을 수행\n",
    "    for iter in range(1, num_iteration+1):\n",
    "        training_pair = training_pairs[iter - 1]  # 현재 반복에 사용할 학습 쌍을 선택\n",
    "        input_tensor = training_pair[0]  # 입력 텐서를 설정\n",
    "        target_tensor = training_pair[1]  # 타겟 텐서를 설정\n",
    "        loss = Model(model, input_tensor, target_tensor, optimizer, criterion)  # 모델 학습 및 손실 계산\n",
    "        total_loss_iterations += loss  # 총 손실값에 현재 손실값을 더함\n",
    "\n",
    "        # 5000번마다 평균 손실값 출력\n",
    "        if iter % 5000 == 0:\n",
    "            average_loss= total_loss_iterations / 5000  # 평균 손실값 계산\n",
    "            total_loss_iterations = 0  # 총 손실값을 0으로 초기화\n",
    "            print('%d %.4f' % (iter, average_loss))  # 현재 반복 횟수와 평균 손실값 출력\n",
    "          \n",
    "    torch.save(model.state_dict(), './mytraining.pt')  # 학습된 모델의 상태를 파일에 저장\n",
    "    return model  # 학습된 모델 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd2079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():  # 평가 시에는 기울기 계산을 하지 않음\n",
    "        input_tensor = tensorFromSentence(input_lang, sentences[0])  # 입력 문장을 텐서로 변환\n",
    "        output_tensor = tensorFromSentence(output_lang, sentences[1])  # 출력 문장을 텐서로 변환\n",
    "        decoded_words = []  # 디코딩된 단어들을 저장할 리스트\n",
    "        output = model(input_tensor, output_tensor)  # 모델을 통해 출력 계산\n",
    "\n",
    "        for ot in range(output.size(0)):  # 출력의 각 타임스텝마다\n",
    "            topv, topi = output[ot].topk(1)  # 최고값(top-k)을 찾아 인덱스 반환\n",
    "\n",
    "            if topi[0].item() == EOS_token:  # EOS 토큰을 만나면 평가를 멈춤\n",
    "                decoded_words.append('<EOS>')  # 디코딩된 단어 리스트에 EOS 추가\n",
    "                break  # 반복문 종료\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi[0].item()])  # 디코딩된 단어 리스트에 단어 추가\n",
    "    return decoded_words  # 디코딩된 단어 리스트 반환\n",
    "\n",
    "def evaluateRandomly(model, input_lang, output_lang, pairs, n=10): # 훈련 데이터셋으로부터 임의의 문장을 가져와서 모델 평가\n",
    "    for i in range(n):  # n개의 랜덤한 쌍에 대해 평가 수행\n",
    "        pair = random.choice(pairs)  # 랜덤하게 쌍 선택\n",
    "        print('input {}'.format(pair[0]))  # 입력 문장 출력\n",
    "        print('output {}'.format(pair[1]))  # 실제 출력 문장 출력\n",
    "        output_words = evaluate(model, input_lang, output_lang, pair)  # 모델을 통해 예측된 출력 계산\n",
    "        output_sentence = ' '.join(output_words)  # 예측된 단어들을 하나의 문장으로 결합\n",
    "        print('predicted {}'.format(output_sentence))  # 예측된 문장 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd0d4e-be46-42cd-baef-f5190478ab65",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6814115",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './eng-fra.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lang1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 입력으로 사용할 영어\u001b[39;00m\n\u001b[0;32m      2\u001b[0m lang2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfra\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 출력으로 사용할 프랑스어\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m input_lang, output_lang, pairs \u001b[38;5;241m=\u001b[39m process_data(lang1, lang2)  \u001b[38;5;66;03m# 데이터 처리 함수 호출하여 언어 객체와 문장 쌍을 생성\u001b[39;00m\n\u001b[0;32m      5\u001b[0m randomize \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(pairs)  \u001b[38;5;66;03m# 문장 쌍 중 랜덤하게 하나를 선택\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom sentence \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(randomize))  \u001b[38;5;66;03m# 랜덤하게 선택된 문장 쌍 출력\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m, in \u001b[0;36mprocess_data\u001b[1;34m(lang1, lang2)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_data\u001b[39m(lang1, lang2):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# 파일을 읽어 데이터프레임으로 변환\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     df \u001b[38;5;241m=\u001b[39m read_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (lang1, lang2), lang1, lang2)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# 두 언어의 문장을 정규화\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     sentence1, sentence2 \u001b[38;5;241m=\u001b[39m read_sentence(df, lang1, lang2)\n",
      "Cell \u001b[1;32mIn[15], line 26\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(loc, lang1, lang2)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(loc, lang1, lang2):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# 파일을 읽어 데이터프레임 생성 (탭으로 구분, 헤더 없음)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(loc, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39m[lang1, lang2])\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './eng-fra.txt'"
     ]
    }
   ],
   "source": [
    "lang1 = 'eng'  # 입력으로 사용할 영어\n",
    "lang2 = 'fra'  # 출력으로 사용할 프랑스어\n",
    "input_lang, output_lang, pairs = process_data(lang1, lang2)  # 데이터 처리 함수 호출하여 언어 객체와 문장 쌍을 생성\n",
    "\n",
    "randomize = random.choice(pairs)  # 문장 쌍 중 랜덤하게 하나를 선택\n",
    "print('random sentence {}'.format(randomize))  # 랜덤하게 선택된 문장 쌍 출력\n",
    "\n",
    "input_size = input_lang.n_words  # 입력 언어의 단어 수 설정\n",
    "output_size = output_lang.n_words  # 출력 언어의 단어 수 설정\n",
    "print('Input : {} Output : {}'.format(input_size, output_size))  # 입력 및 출력 단어 수 출력\n",
    "\n",
    "embed_size = 256  # 임베딩 크기 설정\n",
    "hidden_size = 512  # 은닉층 크기 설정\n",
    "num_layers = 1  # 레이어 수 설정\n",
    "num_iteration = 75000  # 학습 반복 횟수 설정\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)  # 인코더 객체 생성\n",
    "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)  # 디코더 객체 생성\n",
    "                                                                     # 디코더의 첫번째 입력으로 <SOS> 토큰이 제공되고, 인코더의 마지막 은닉 상태가 디코더의 첫번째 은닉 상태로 제공된다.\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)  # Seq2Seq 모델 객체 생성 및 디바이스로 이동\n",
    "\n",
    "print(encoder)  # 인코더 객체 출력\n",
    "print(decoder)  # 디코더 객체 출력\n",
    "\n",
    "model = trainModel(model, input_lang, output_lang, pairs, num_iteration)  # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25248205-c402-4cae-853d-a94a43f5f510",
   "metadata": {},
   "source": [
    "### 임의의 문장에 대한 평가 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa2807a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evaluateRandomly(model, input_lang, output_lang, pairs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(model, input_lang, output_lang, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0dc46-f882-45f2-9b79-422fa8959ed6",
   "metadata": {},
   "source": [
    "### 어텐션이 적용된 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size  # 은닉층 크기 설정\n",
    "        self.output_size = output_size  # 출력 크기 설정\n",
    "        self.dropout_p = dropout_p  # 드롭아웃 확률 설정\n",
    "        self.max_length = max_length  # 최대 길이 설정\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)  # 임베딩 레이어 생성\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)  # 어텐션 가중치를 계산하는 선형 레이어 생성\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)  # 어텐션 결합을 위한 선형 레이어 생성\n",
    "        self.dropout = nn.Dropout(self.dropout_p)  # 드롭아웃 레이어 생성\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)  # GRU 레이어 생성\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)  # 출력 레이어 생성\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)  # 입력을 임베딩하고 차원 변환\n",
    "        embedded = self.dropout(embedded)  # 드롭아웃 적용\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)  # 어텐션 가중치 계산\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))  # 어텐션 적용\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)  # 임베딩과 어텐션 결합\n",
    "        output = self.attn_combine(output).unsqueeze(0)  # 결합된 결과를 선형 변환 후 차원 변환\n",
    "\n",
    "        output = F.relu(output)  # ReLU 활성화 함수 적용\n",
    "        output, hidden = self.gru(output, hidden)  # GRU를 통해 출력과 새로운 은닉 상태 계산\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)  # 출력에 소프트맥스 함수 적용하여 로그 확률 계산\n",
    "        return output, hidden, attn_weights  # 출력, 은닉 상태, 어텐션 가중치 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83feb456-2564-431b-85c5-2305cdd93611",
   "metadata": {},
   "source": [
    "### 어텐션 디코더 모델 학습을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()  # 시작 시간 기록\n",
    "    plot_losses = []  # 손실 값 저장을 위한 리스트\n",
    "    print_loss_total = 0  # 출력할 손실 값 총합 초기화\n",
    "    plot_loss_total = 0  # 그래프에 그릴 손실 값 총합 초기화\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)  # 인코더 옵티마이저 설정\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)  # 디코더 옵티마이저 설정\n",
    "    training_pairs = [tensorsFromPair(input_lang, output_lang, random.choice(pairs))\n",
    "                      for i in range(n_iters)]  # 학습 쌍 생성\n",
    "    criterion = nn.NLLLoss()  # 손실 함수 설정\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]  # 현재 반복에 사용할 학습 쌍 선택\n",
    "        input_tensor = training_pair[0]  # 입력 텐서 설정\n",
    "        target_tensor = training_pair[1]  # 타겟 텐서 설정\n",
    "        loss = Model(model, input_tensor, target_tensor, decoder_optimizer, criterion)  # 모델 학습 및 손실 계산\n",
    "        print_loss_total += loss  # 출력할 손실 값에 현재 손실 값 더하기\n",
    "        plot_loss_total += loss  # 그래프 손실 값에 현재 손실 값 더하기\n",
    "\n",
    "        if iter % print_every == 0:  # 지정된 출력 주기마다\n",
    "            print_loss_avg = print_loss_total / print_every  # 평균 손실 값 계산\n",
    "            print_loss_total = 0  # 출력할 손실 값 초기화\n",
    "            print('%d,  %.4f' % (iter, print_loss_avg))  # 현재 반복과 평균 손실 값 출력\n",
    "\n",
    "        if iter % plot_every == 0:  # 지정된 그래프 주기마다\n",
    "            plot_loss_avg = plot_loss_total / plot_every  # 평균 손실 값 계산\n",
    "            plot_losses.append(plot_loss_avg)  # 손실 값 리스트에 추가\n",
    "            plot_loss_total = 0  # 그래프 손실 값 초기화\n",
    "\n",
    "    showPlot(plot_losses)  # 손실 값 그래프 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77553d75-bfe2-43f7-933b-849273b59529",
   "metadata": {},
   "source": [
    "### 어텐션 디코더 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df879d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_lang' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m      3\u001b[0m num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 4\u001b[0m input_size \u001b[38;5;241m=\u001b[39m input_lang\u001b[38;5;241m.\u001b[39mn_words\n\u001b[0;32m      5\u001b[0m output_size \u001b[38;5;241m=\u001b[39m output_lang\u001b[38;5;241m.\u001b[39mn_words\n\u001b[0;32m      7\u001b[0m encoder1 \u001b[38;5;241m=\u001b[39m Encoder(input_size, hidden_size, embed_size, num_layers)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_lang' is not defined"
     ]
    }
   ],
   "source": [
    "embed_size = 256  # 임베딩 크기 설정\n",
    "hidden_size = 512  # 은닉층 크기 설정\n",
    "num_layers = 1  # 레이어 수 설정\n",
    "input_size = input_lang.n_words  # 입력 언어의 단어 수 설정\n",
    "output_size = output_lang.n_words  # 출력 언어의 단어 수 설정\n",
    "\n",
    "encoder1 = Encoder(input_size, hidden_size, embed_size, num_layers)  # 인코더 객체 생성\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_size, dropout_p=0.1).to(device)  # 어텐션 디코더 객체 생성 및 디바이스로 이동\n",
    "\n",
    "print(encoder1)  # 인코더 객체 출력\n",
    "print(attn_decoder1)  # 어텐션 디코더 객체 출력\n",
    "\n",
    "attn_model = trainIters(encoder1, attn_decoder1, 75000, print_every=5000, plot_every=100, learning_rate=0.01)  # 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "201fd8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.8/43.8 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chohj\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.1 MB 6.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/9.1 MB 7.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/9.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.1/9.1 MB 6.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.4/9.1 MB 6.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.7/9.1 MB 6.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.0/9.1 MB 6.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.2/9.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.5/9.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.8/9.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.1/9.1 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.4/9.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.6/9.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.9/9.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.2/9.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.3/9.1 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.6/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.9/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.2/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.5/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.8/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.0/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.6/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.9/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.2/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.4/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.7/9.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.0/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.3/9.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.5/9.1 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.8/9.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.7 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 297.0/401.7 kB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 401.7/401.7 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.3 kB ? eta -:--:--\n",
      "   ---------------------------------------  286.7/287.3 kB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.3/287.3 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.2 MB 7.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.2 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.2 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.2 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.2 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.2\n",
      "Collecting pytorch-transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\chohj\\appdata\\roaming\\python\\python311\\site-packages (from pytorch-transformers) (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from pytorch-transformers) (1.24.3)\n",
      "Collecting boto3 (from pytorch-transformers)\n",
      "  Downloading boto3-1.34.116-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from pytorch-transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from pytorch-transformers) (4.65.0)\n",
      "Requirement already satisfied: regex in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from pytorch-transformers) (2023.10.3)\n",
      "Collecting sentencepiece (from pytorch-transformers)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting sacremoses (from pytorch-transformers)\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\chohj\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.0.0->pytorch-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (3.1.3)\n",
      "Collecting botocore<1.35.0,>=1.34.116 (from boto3->pytorch-transformers)\n",
      "  Downloading botocore-1.34.116-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from boto3->pytorch-transformers) (1.0.1)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->pytorch-transformers)\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (2024.2.2)\n",
      "Requirement already satisfied: click in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from sacremoses->pytorch-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from sacremoses->pytorch-transformers) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from tqdm->pytorch-transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from botocore<1.35.0,>=1.34.116->boto3->pytorch-transformers) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chohj\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.116->boto3->pytorch-transformers) (1.16.0)\n",
      "Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "   ---------------------------------------- 0.0/176.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 176.4/176.4 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading boto3-1.34.116-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.3/139.3 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "   ---------------------------------------- 0.0/897.5 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 348.2/897.5 kB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 634.9/897.5 kB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 849.9/897.5 kB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 897.5/897.5 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 204.8/991.5 kB 12.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 532.5/991.5 kB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 819.2/991.5 kB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  983.0/991.5 kB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading botocore-1.34.116-py3-none-any.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/12.3 MB 7.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.5/12.3 MB 6.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.7/12.3 MB 6.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/12.3 MB 6.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.5/12.3 MB 6.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.8/12.3 MB 6.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.1/12.3 MB 6.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.4/12.3 MB 6.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.7/12.3 MB 6.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/12.3 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.2/12.3 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/12.3 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.8/12.3 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.0/12.3 MB 5.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.3/12.3 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.6/12.3 MB 5.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.9/12.3 MB 5.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.3 MB 5.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.4/12.3 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.7/12.3 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.0/12.3 MB 5.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.3/12.3 MB 5.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.6/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.8/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.1/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.4/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.7/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.9/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.2/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.5/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.8/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.1/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.3/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.6/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.9/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.1/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.4/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.1/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.6/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.9/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.2/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.2/82.2 kB 4.5 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, sacremoses, botocore, s3transfer, boto3, pytorch-transformers\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.64\n",
      "    Uninstalling botocore-1.31.64:\n",
      "      Successfully uninstalled botocore-1.31.64\n",
      "Successfully installed boto3-1.34.116 botocore-1.34.116 pytorch-transformers-1.2.0 s3transfer-0.10.1 sacremoses-0.1.1 sentencepiece-0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.7.0 requires botocore<1.31.65,>=1.31.16, but you have botocore 1.34.116 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#10.2.1 Bert\n",
    "!pip install transformers\n",
    "!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b91e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification # 버트 사용을 위한 라이브러리\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix # 모델 평가를 위해 사\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa39b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 불러오기\n",
    "train_df = pd.read_csv('./training.txt', sep='\\t')\n",
    "valid_df = pd.read_csv('./validing.txt', sep='\\t')\n",
    "test_df = pd.read_csv('./testing.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e620c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 데이터셋 중 일부만 사용 (10%)\n",
    "train_df = train_df.sample(frac=0.1, random_state=500)\n",
    "valid_df = valid_df.sample(frac=0.1, random_state=500)\n",
    "test_df = test_df.sample(frac=0.1, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8506022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "class Datasets(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 1] # 인덱스 1번 사용(document)\n",
    "        label = self.df.iloc[idx, 2] # 인덱스 2번 사용(label)\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97277c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋의 데이터를 데이터로더로 전달\n",
    "train_dataset = Datasets(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "valid_dataset = Datasets(valid_df)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = Datasets(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "106307e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 버트 토크나이저 내려받기\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # 사전 훈련된 버트의 토크나이저를 사용. 모든 문장을 소문자로 대체\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased') # 버트 모델 생성\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c0f5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 모델 저장\n",
    "def save_checkpoint(save_path, model, valid_loss): # 모델 평가를 위해 훈련 과정을 저장\n",
    "    if save_path is None:  # 저장 경로가 지정되지 않은 경우\n",
    "        return    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),  # 모델 상태 딕셔너리\n",
    "                  'valid_loss': valid_loss}  # 검증 손실 값\n",
    "    \n",
    "    torch.save(state_dict, save_path)  # 상태 딕셔너리를 지정된 경로에 저장\n",
    "    print(f'Model saved to ==> {save_path}')  # 저장 완료 메시지 출력\n",
    "\n",
    "def load_checkpoint(load_path, model): # save_checkpoint 함수에서 저장된 모델을 가져옴   \n",
    "    if load_path is None:  # 로드 경로가 지정되지 않은 경우\n",
    "        return    \n",
    "    state_dict = torch.load(load_path, map_location=device)  # 지정된 경로에서 상태 딕셔너리를 로드하고 디바이스에 맵핑\n",
    "    print(f'Model loaded from <== {load_path}')  # 로드 완료 메시지 출력\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])  # 모델의 상태를 로드한 상태 딕셔너리로 설정\n",
    "    return state_dict['valid_loss']  # 검증 손실 값을 반환\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list): # 훈련, 검증에 대한 오차와 에포크를 저장\n",
    "    if save_path is None:  # 저장 경로가 지정되지 않은 경우\n",
    "        return    \n",
    "    state_dict = {'train_loss_list': train_loss_list,  # 학습 손실 리스트\n",
    "                  'valid_loss_list': valid_loss_list,  # 검증 손실 리스트\n",
    "                  'global_steps_list': global_steps_list}  # 글로벌 스텝 리스트\n",
    "    torch.save(state_dict, save_path)  # 상태 딕셔너리를 지정된 경로에 저장\n",
    "    print(f'Metrics saved to ==> {save_path}')  # 저장 완료 메시지 출력\n",
    "\n",
    "def load_metrics(load_path): # save_metrics에 저장해 둔 정보를 불러옴\n",
    "    if load_path is None:  # 로드 경로가 지정되지 않은 경우\n",
    "        return    \n",
    "    state_dict = torch.load(load_path, map_location=device)  # 지정된 경로에서 상태 딕셔너리를 로드하고 디바이스에 맵핑\n",
    "    print(f'Metrics loaded from <== {load_path}')  # 로드 완료 메시지 출력\n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']  # 각 리스트를 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0871e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 함수 정의\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion=nn.BCELoss(), # 좋고 나쁨만 있으므로 BinaryCrossEntropy 사용\n",
    "          num_epochs=5,\n",
    "          eval_every=len(train_loader) // 2,\n",
    "          best_valid_loss=float(\"Inf\")):\n",
    "    \n",
    "    total_correct = 0.0  # 정확하게 예측한 총 개수 초기화\n",
    "    total_len = 0.0  # 전체 데이터 개수 초기화\n",
    "    running_loss = 0.0  # 학습 중 손실 값 초기화\n",
    "    valid_running_loss = 0.0  # 검증 중 손실 값 초기화\n",
    "    global_step = 0  # 전체 스텝 수 초기화\n",
    "    train_loss_list = []  # 학습 손실 값을 저장할 리스트\n",
    "    valid_loss_list = []  # 검증 손실 값을 저장할 리스트\n",
    "    global_steps_list = []  # 스텝 수를 저장할 리스트\n",
    "\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    for epoch in range(num_epochs):\n",
    "        for text, label in train_loader:\n",
    "            optimizer.zero_grad()  # 옵티마이저의 기울기를 초기화        \n",
    "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]  # 텍스트를 토큰화\n",
    "            padded_list = [e + [0] * (512 - len(e)) for e in encoded_list]  # 인코딩 결과에 제로패딩 추가\n",
    "        \n",
    "            sample = torch.tensor(padded_list)\n",
    "            sample, label = sample.to(device), label.to(device)  # 데이터를 디바이스로 이동\n",
    "            labels = label.clone().detach()\n",
    "            outputs = model(sample, labels=labels)  # 모델에 입력하여 출력 계산\n",
    "            loss, logits = outputs\n",
    "\n",
    "            pred = torch.argmax(F.softmax(logits, dim=1), dim=1)  # 예측값 계산 (가장 큰 값 반환)\n",
    "            correct = pred.eq(labels)  # 예측이 맞았는지 확인\n",
    "            total_correct += correct.sum().item()  # 맞은 개수 누적\n",
    "            total_len += len(labels)  # 전체 데이터 개수 누적\n",
    "            running_loss += loss.item()  # 손실 값 누적\n",
    "            loss.backward()  # 역전파 수행\n",
    "            optimizer.step()  # 옵티마이저를 통해 파라미터 업데이트\n",
    "            global_step += 1  # 전체 스텝 수 증가\n",
    "\n",
    "            if global_step % eval_every == 0:  # 지정된 스텝마다 검증 수행\n",
    "                model.eval()  # 모델을 평가 모드로 전환\n",
    "                with torch.no_grad():  # 기울기 계산 중지                    \n",
    "                    for text, label in valid_loader:\n",
    "                        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]  # 텍스트를 토큰화\n",
    "                        padded_list = [e + [0] * (512 - len(e)) for e in encoded_list]  # 패딩 추가        \n",
    "                        sample = torch.tensor(padded_list)\n",
    "                        sample, label = sample.to(device), label.to(device)  # 데이터를 디바이스로 이동\n",
    "                        labels = label.clone().detach()\n",
    "                        outputs = model(sample, labels=labels)  # 모델에 입력하여 출력 계산\n",
    "                        loss, logits = outputs                        \n",
    "                        valid_running_loss += loss.item()  # 검증 손실 값 누적\n",
    "\n",
    "                average_train_loss = running_loss / eval_every  # 평균 학습 손실 값 계산\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)  # 평균 검증 손실 값 계산\n",
    "                train_loss_list.append(average_train_loss)  # 학습 손실 값을 리스트에 추가\n",
    "                valid_loss_list.append(average_valid_loss)  # 검증 손실 값을 리스트에 추가\n",
    "                global_steps_list.append(global_step)  # 전체 스텝 수를 리스트에 추가\n",
    "\n",
    "                running_loss = 0.0  # 학습 손실 값 초기화                \n",
    "                valid_running_loss = 0.0  # 검증 손실 값 초기화\n",
    "                model.train()  # 모델을 다시 학습 모드로 전환\n",
    "\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, global_step, num_epochs * len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                if best_valid_loss > average_valid_loss:  # 검증 손실 값이 가장 낮을 때 모델 저장\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint('../chap10/model.pt', model, best_valid_loss)\n",
    "                    save_metrics('../chap10/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics('../chap10/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)  # 마지막으로 메트릭 저장\n",
    "    print('훈련 종료!')  # 훈련 종료 메시지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f69dac7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 모델의 파라미터 미세 조정 및 모델 훈련\u001b[39;00m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m train(model\u001b[38;5;241m=\u001b[39mmodel, optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n",
      "Cell \u001b[1;32mIn[8], line 37\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, num_epochs, eval_every, best_valid_loss)\u001b[0m\n\u001b[0;32m     35\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# 손실 값 누적\u001b[39;00m\n\u001b[0;32m     36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# 역전파 수행\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# 옵티마이저를 통해 파라미터 업데이트\u001b[39;00m\n\u001b[0;32m     38\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 전체 스텝 수 증가\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m eval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# 지정된 스텝마다 검증 수행\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[0;32m    144\u001b[0m         exp_avgs,\n\u001b[0;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    147\u001b[0m         state_steps,\n\u001b[0;32m    148\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    149\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    150\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    151\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    152\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    153\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    154\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    155\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    156\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    157\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    158\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    159\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m func(params,\n\u001b[0;32m    282\u001b[0m      grads,\n\u001b[0;32m    283\u001b[0m      exp_avgs,\n\u001b[0;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    286\u001b[0m      state_steps,\n\u001b[0;32m    287\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    288\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    289\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    290\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    291\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    292\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    293\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    294\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    295\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    296\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    297\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\optim\\adam.py:393\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m--> 393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델의 파라미터 미세 조정 및 모델 훈련\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "train(model=model, optimizer=optimizer) # 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2abbb6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== e:/torch/chap10/data/metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 오차 정보를 그래프로 확인\n",
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics('../chap10/data/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb68692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 함수 정의\n",
    "def evaluate(model, test_loader):\n",
    "    y_pred = []  # 예측값을 저장할 리스트\n",
    "    y_true = []  # 실제값을 저장할 리스트\n",
    "\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():  # 기울기 계산 중지\n",
    "        for text, label in test_loader:\n",
    "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]  # 텍스트를 토큰화\n",
    "            padded_list = [e + [0] * (512 - len(e)) for e in encoded_list]  # 패딩 추가\n",
    "        \n",
    "            sample = torch.tensor(padded_list)\n",
    "            sample, label = sample.to(device), label.to(device)  # 데이터를 디바이스로 이동\n",
    "            labels = label.clone().detach()  \n",
    "            output = model(sample, labels=labels)  # 모델에 입력하여 출력 계산\n",
    "            \n",
    "            _, output = output  # 출력값과 손실값 분리\n",
    "            y_pred.extend(torch.argmax(output, 1).tolist())  # 예측값을 리스트에 추가\n",
    "            y_true.extend(labels.tolist())  # 실제값을 리스트에 추가\n",
    "                    \n",
    "    print('Classification 결과:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))  # 분류 결과 출력\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])  # 혼동 행렬 계산\n",
    "    ax = plt.subplot()  # 서브플롯 생성\n",
    "    sns.heatmap(cm, annot=True, ax=ax, cmap='Blues', fmt=\"d\")  # 혼동 행렬을 히트맵으로 출력\n",
    "    \n",
    "    ax.set_title('Confusion Matrix')  # 제목 설정\n",
    "    ax.set_xlabel('Predicted Labels')  # x축 라벨 설정\n",
    "    ax.set_ylabel('True Labels')  # y축 라벨 설정\n",
    "    ax.xaxis.set_ticklabels(['0', '1'])  # x축 틱 라벨 설정\n",
    "    ax.yaxis.set_ticklabels(['0', '1'])  # y축 틱 라벨 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97dfe435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== e:/torch/chap10/data/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-f9df6714cef0>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification 결과:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5091    1.0000    0.6747       558\n",
      "           0     0.0000    0.0000    0.0000       538\n",
      "\n",
      "    accuracy                         0.5091      1096\n",
      "   macro avg     0.2546    0.5000    0.3374      1096\n",
      "weighted avg     0.2592    0.5091    0.3435      1096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "best_model = model.to(device)\n",
    "load_checkpoint('../chap10/model.pt', best_model)\n",
    "evaluate(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d152143-4503-4e8f-ae60-bb959dcf39b3",
   "metadata": {},
   "source": [
    "# 10.3 한국어 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14558a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2479170d143d44539673ef570dd333a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chohj\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\chohj\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbd53daa9464323803d3715a640d8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689420025d884220b44a7ae3097ba3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chohj\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c2243fea4544cfa56413524655a825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 라이브러리 불러오기\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased') # 한국어를 위한 버트 토크나이저 'bert-base-multilingual-cased' 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe6d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '나는', '파', '##이', '##토', '##치를', '이', '##용한', '딥', '##러', '##닝', '##을', '학', '##습', '##중', '##이다', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# 문장의 토크나이징\n",
    "text = \"나는 파이토치를 이용한 딥러닝을 학습중이다.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\" # 문장의 시작은 [CLS], 문장의 끝은 [SEP]로 형태를 맞춘다\n",
    "tokenized_text = tokenizer.tokenize(marked_text) # 사전 훈련된 버트 토크나이저를 이용해서 문장을 단어로 쪼갠다\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3740f31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "과             8,898\n",
      "##수          15,891\n",
      "##원에         108,280\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##가          11,287\n",
      "많             9,249\n",
      "##았다         27,303\n",
      ".               119\n",
      "친             9,781\n",
      "##구          17,196\n",
      "##가          11,287\n",
      "나             8,982\n",
      "##에게         26,212\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##했다         12,490\n",
      ".               119\n",
      "백             9,331\n",
      "##설          31,928\n",
      "##공          28,000\n",
      "##주는         100,633\n",
      "독             9,088\n",
      "##이          10,739\n",
      "든             9,115\n",
      "사             9,405\n",
      "##과          11,882\n",
      "##를          11,513\n",
      "먹             9,266\n",
      "##었다         17,706\n",
      ".               119\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# 모델을 훈련시킬 텍스트 정의\n",
    "text = \"과수원에 사과가 많았다.\" \\\n",
    "       \"친구가 나에게 사과했다.\"\\\n",
    "       \"백설공주는 독이 든 사과를 먹었다.\"\n",
    "\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\" # 앞에는 [CLS], 뒤에는 [SEP]를 추가\n",
    "tokenized_text = tokenizer.tokenize(marked_text) # 문장을 토큰으로 분리\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text) # 토큰 문자열에 인덱스를 매핑\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens): # 단어와 인덱스를 출력\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da9f047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 문장 인식 단위 지정\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9a81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 텐서로 변환\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2637806e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999c1bddf7554da29187827d3ddfca72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased',\n",
    "                                  output_hidden_states = True,)\n",
    "\n",
    "model.eval() # 모델을 평가 모드로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba79d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "with torch.no_grad(): # 모델을 평가할 때 기울기 사용 X\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2] # 네트워크의 은닉 상태를 가져온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e61815e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계층 수: 13   (initial embeddings + 12 BERT layers)\n",
      "배치 수: 1\n",
      "토큰 수: 33\n",
      "은닉층 유닛 수: 768\n"
     ]
    }
   ],
   "source": [
    "# 모델의 은닉 상태 정보 확인\n",
    "print (\"계층 수:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"배치 수:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"토큰 수:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"은닉층 유닛 수:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c79e83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "은닉 상태의 유형:  <class 'tuple'>\n",
      "각 계층에서의 텐서 형태:  torch.Size([1, 33, 768])\n"
     ]
    }
   ],
   "source": [
    "print('은닉 상태의 유형: ', type(hidden_states))\n",
    "print('각 계층에서의 텐서 형태: ', hidden_states[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9633fe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 33, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서의 형태 변경\n",
    "token_embeddings = torch.stack(hidden_states, dim=0) # 각 계층의 텐서 결합은 stack을 사용\n",
    "token_embeddings.size() # 최종 텐서의 형태를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d777453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 33, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.squeeze(token_embeddings, dim=1) # 배치 차원(1) 제거\n",
    "token_embeddings.size() # 배치 차원 제거 후 최종 텐서의 형태를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa6a4d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 13, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서 차원 변경\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b2f7874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태는: 33 x 3072\n"
     ]
    }
   ],
   "source": [
    "# 각 단어에 대한 벡터 형태 확인\n",
    "token_vecs_cat = []  # 형태가 [33 x (33 x 768)]인 벡터를 [33 x 25344]로 변경하여 저장\n",
    "\n",
    "# token_embeddings는 [33 x 12 x 768] 형태의 텐서를 갖는다\n",
    "for token in token_embeddings:\n",
    "    # 마지막 4개의 레이어의 은닉 상태 벡터를 이어붙인다\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "# 결과 벡터의 형태를 출력\n",
    "print('형태는: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7621bc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태는: 33 x 768\n"
     ]
    }
   ],
   "source": [
    "# 계층을 결합하여 최종 단어 벡터 생성\n",
    "token_vecs_sum = [] # [33x768] 형태의 토큰을 벡터로 저장\n",
    "for token in token_embeddings: # 'token_embeddings'는 [33x12x768] 형태의 토큰을 갖는다\n",
    "    sum_vec = torch.sum(token[-4:], dim=0) # 마지막 4개 계층의 벡터를 합산\n",
    "    token_vecs_sum.append(sum_vec) # sum_vec를 사용하여 토큰을 표현\n",
    "print ('형태는: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a14ae7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 임베딩 벡터의 형태: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# 문장 벡터\n",
    "token_vecs = hidden_states[-2][0] #[33x768]\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "print (\"최종 임베딩 벡터의 형태:\", sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0b581d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 과\n",
      "2 ##수\n",
      "3 ##원에\n",
      "4 사\n",
      "5 ##과\n",
      "6 ##가\n",
      "7 많\n",
      "8 ##았다\n",
      "9 .\n",
      "10 친\n",
      "11 ##구\n",
      "12 ##가\n",
      "13 나\n",
      "14 ##에게\n",
      "15 사\n",
      "16 ##과\n",
      "17 ##했다\n",
      "18 .\n",
      "19 백\n",
      "20 ##설\n",
      "21 ##공\n",
      "22 ##주는\n",
      "23 독\n",
      "24 ##이\n",
      "25 든\n",
      "26 사\n",
      "27 ##과\n",
      "28 ##를\n",
      "29 먹\n",
      "30 ##었다\n",
      "31 .\n",
      "32 [SEP]\n"
     ]
    }
   ],
   "source": [
    "# 토큰과 인덱스 출력\n",
    "for i, token_str in enumerate(tokenized_text): # torkenized_text에서 토큰들을 꺼내서 인덱스와 함께 출력\n",
    "    print (i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb56c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사과가 많았다 tensor([-0.5844, -4.0836,  0.4906,  0.8915, -1.8054])\n",
      "나에게 사과했다 tensor([-0.8631, -3.4047, -0.7351,  0.9805, -2.6700])\n",
      "사과를 먹었다 tensor([ 0.6756, -0.3618,  0.0586,  2.2050, -2.4193])\n"
     ]
    }
   ],
   "source": [
    "# 단어 벡터 확인\n",
    "print(\"사과가 많았다\", str(token_vecs_sum[6][:5]))\n",
    "print(\"나에게 사과했다\", str(token_vecs_sum[10][:5]))\n",
    "print(\"사과를 먹었다\", str(token_vecs_sum[19][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbc2e65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*유사한* 의미에 대한 벡터 유사성:  0.86\n",
      "*다른* 의미에 대한 벡터 유사성:  0.91\n"
     ]
    }
   ],
   "source": [
    "# 코사인 유사도 계산\n",
    "from scipy.spatial.distance import cosine\n",
    "diff_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[27]) # '사과가 많았다'와 '나에게 사과했다'에서 단어 '사과' 사이의 코사인 유사도 계싼\n",
    "same_apple = 1 - cosine(token_vecs_sum[5], token_vecs_sum[16]) # '사과가 많았다'와 '사과를 먹었다'에 있는 '사과'사이의 코사인 유사도를 계산\n",
    "print('*유사한* 의미에 대한 벡터 유사성:  %.2f' % same_apple)\n",
    "print('*다른* 의미에 대한 벡터 유사성:  %.2f' % diff_apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c53aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
